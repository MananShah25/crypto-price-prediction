{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjL4xyw-lmeC",
        "outputId": "94ccf9cf-821c-4b09-9283-5f2a38ad14bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BTC-USD: 61 rows\n",
            "Loaded ETH-USD: 61 rows\n",
            "Loaded ADA-USD: 61 rows\n",
            "Loaded SOL-USD: 61 rows\n",
            "Loaded XRP-USD: 61 rows\n",
            "Loaded DOGE-USD: 61 rows\n",
            "Loaded DOT-USD: 61 rows\n",
            "Loaded LTC-USD: 61 rows\n",
            "Loaded LINK-USD: 61 rows\n",
            "Loaded AVAX-USD: 61 rows\n",
            "\n",
            "Cryptocurrency Price Direction Prediction Results\n",
            "\n",
            "\n",
            "BTC-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.125, Recall: 0.200, F1: 0.154, Accuracy: 0.267\n",
            "\n",
            "BTC-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.333, Recall: 0.750, F1: 0.462, Accuracy: 0.417\n",
            "\n",
            "ETH-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.400, Recall: 0.500, F1: 0.444, Accuracy: 0.667\n",
            "\n",
            "ETH-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.400, Recall: 0.500, F1: 0.444, Accuracy: 0.545\n",
            "\n",
            "ADA-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.273, Recall: 0.600, F1: 0.375, Accuracy: 0.333\n",
            "\n",
            "ADA-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.250, Recall: 0.500, F1: 0.333, Accuracy: 0.273\n",
            "\n",
            "SOL-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.333, Recall: 0.600, F1: 0.429, Accuracy: 0.467\n",
            "\n",
            "SOL-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.286, Recall: 0.500, F1: 0.364, Accuracy: 0.364\n",
            "\n",
            "XRP-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.300, Recall: 0.750, F1: 0.429, Accuracy: 0.467\n",
            "\n",
            "XRP-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.500, Recall: 1.000, F1: 0.667, Accuracy: 0.700\n",
            "\n",
            "DOGE-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.333, Recall: 0.600, F1: 0.429, Accuracy: 0.467\n",
            "\n",
            "DOGE-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.400, Recall: 1.000, F1: 0.571, Accuracy: 0.500\n",
            "\n",
            "DOT-USD - Next-Day Direction\n",
            "  Training window: 18 days, Features: 8\n",
            "  Precision: 0.250, Recall: 0.500, F1: 0.333, Accuracy: 0.600\n",
            "\n",
            "DOT-USD - Significant Moves (±0.8%)\n",
            "  Precision: 0.500, Recall: 1.000, F1: 0.667, Accuracy: 0.500\n",
            "\n",
            "LTC-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.400, Recall: 0.333, F1: 0.364, Accuracy: 0.533\n",
            "\n",
            "LTC-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.500, Recall: 0.333, F1: 0.400, Accuracy: 0.571\n",
            "\n",
            "LINK-USD - Next-Day Direction\n",
            "  Training window: 12 days, Features: 21\n",
            "  Precision: 0.250, Recall: 0.400, F1: 0.308, Accuracy: 0.400\n",
            "\n",
            "LINK-USD - Significant Moves (±0.5%)\n",
            "  Precision: 0.250, Recall: 0.400, F1: 0.308, Accuracy: 0.357\n",
            "\n",
            "AVAX-USD - Next-Day Direction\n",
            "  Training window: 16 days, Features: 8\n",
            "  Precision: 0.333, Recall: 0.500, F1: 0.400, Accuracy: 0.500\n",
            "\n",
            "AVAX-USD - Significant Moves (±0.3%)\n",
            "  Precision: 0.333, Recall: 0.500, F1: 0.400, Accuracy: 0.455\n",
            "\n",
            "\n",
            "Summary Statistics\n",
            "\n",
            "Average Performance:\n",
            "  Precision: 0.300\n",
            "  Recall: 0.498\n",
            "  F1-Score: 0.366\n",
            "  Accuracy: 0.470\n",
            "\n",
            "Assets Evaluated: 10 out of 10\n",
            "\n",
            "Best Performer: ETH-USD (F1: 0.444)\n",
            "Weakest Performer: BTC-USD (F1: 0.154)\n",
            "\n",
            "Modeling complete\n"
          ]
        }
      ],
      "source": [
        "# Cryptocurrency Price Direction Prediction Model: Using logistic regression with technical indicators to predict next-day price movements\n",
        "\n",
        "# Installing required libraries\n",
        "!pip install ta yfinance scikit-learn matplotlib seaborn -q\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ta\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# asset-specific feature configurations - some assets performing better with fewer, cleaner features to reduce noise\n",
        "asset_features = {\n",
        "  'DOT-USD': [\n",
        "    'rsi_14', 'macd', 'sma_7', 'sma_14', 'momentum',\n",
        "    'bb_position', 'ret_1', 'sma_crossover'\n",
        "  ],\n",
        "  'AVAX-USD': [\n",
        "    'rsi_14', 'rsi_7', 'macd', 'sma_7', 'momentum',\n",
        "    'bb_position', 'ret_1', 'vol_7'\n",
        "  ],\n",
        "  'default': [\n",
        "    'rsi_14', 'rsi_7', 'macd', 'sma_7', 'ema_7',\n",
        "    'sma_14', 'ema_14', 'vol_7', 'momentum', 'bb_width', 'bb_position',\n",
        "    'ret_1', 'ret_3', 'range_3',\n",
        "    'rsi_14_lag1', 'macd_lag1', 'sma_7_lag1', 'bb_width_lag1',\n",
        "    'rsi_macd_interaction', 'momentum_volatility_ratio', 'sma_crossover'\n",
        "  ]\n",
        "}\n",
        "\n",
        "# training window and threshold configurations per asset\n",
        "#(problematic assets uses larger training windows and adjusted thresholds)\n",
        "asset_config = {\n",
        "  'DOT-USD': {\n",
        "    'min_train': 18,\n",
        "    'threshold_big_move': 0.008,\n",
        "    'model_type': 'lr',\n",
        "    'skip_if_zeros': True\n",
        "  },\n",
        "  'AVAX-USD': {\n",
        "    'min_train': 16,\n",
        "    'threshold_big_move': 0.003,\n",
        "    'model_type': 'lr',\n",
        "    'skip_if_zeros': False\n",
        "  },\n",
        "  'default': {\n",
        "    'min_train': 12,\n",
        "    'threshold_big_move': 0.005,\n",
        "    'model_type': 'lr',\n",
        "    'skip_if_zeros': False\n",
        "  }\n",
        "}\n",
        "\n",
        "# defining cryptocurrency tickers and data parameters\n",
        "tickers = [\n",
        "  'BTC-USD', 'ETH-USD', 'ADA-USD', 'SOL-USD', 'XRP-USD',\n",
        "  'DOGE-USD', 'DOT-USD', 'LTC-USD', 'LINK-USD', 'AVAX-USD'\n",
        "]\n",
        "days_to_fetch = 60  # fetching extra data for indicator calculation\n",
        "model_days = 30     # using most recent 30 days for modeling\n",
        "\n",
        "def fetch_crypto_data(tickers, days):\n",
        "  # fetching OHLCV data for cryptocurrency tickers from Yahoo Finance.\n",
        "  # handling various column naming conventions and standardizing output.\n",
        "  today = pd.Timestamp('today').normalize()\n",
        "  start = today - pd.Timedelta(days=days+2)\n",
        "  data = {}\n",
        "\n",
        "  for ticker in tickers:\n",
        "    try:\n",
        "      df = yf.download(ticker, start=start, end=today, interval='1d', progress=False)\n",
        "      if df.empty:\n",
        "        print(f\"No data for {ticker}\")\n",
        "        continue\n",
        "      df = df.reset_index()\n",
        "\n",
        "      # standardizing column names to lowercase\n",
        "      standardized_cols = []\n",
        "      for col in df.columns:\n",
        "        if isinstance(col, tuple):\n",
        "          cleaned = '_'.join(filter(None, [str(s).strip() for s in col]))\n",
        "        else:\n",
        "          cleaned = str(col)\n",
        "        standardized_cols.append(cleaned.lower().replace(' ', '_').replace('-', '_').replace('.', ''))\n",
        "      df.columns = standardized_cols\n",
        "\n",
        "      # ensuring date column exists\n",
        "      if 'date' not in df.columns and 'index' in df.columns:\n",
        "        df = df.rename(columns={'index': 'date'})\n",
        "      if 'date' not in df.columns:\n",
        "        continue\n",
        "      df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "      # ensuring close price column exists\n",
        "      close_col = None\n",
        "      if 'close' in df.columns:\n",
        "        close_col = 'close'\n",
        "      elif 'adj_close' in df.columns:\n",
        "        close_col = 'adj_close'\n",
        "      else:\n",
        "        for col in df.columns:\n",
        "          if col.startswith('close_') or col.startswith('adj_close_'):\n",
        "            close_col = col\n",
        "            break\n",
        "\n",
        "      if close_col and close_col != 'close':\n",
        "        df = df.rename(columns={close_col: 'close'})\n",
        "      elif not close_col:\n",
        "        continue\n",
        "\n",
        "      # ensuring all OHLCV columns exist\n",
        "      for col_name in ['open', 'high', 'low', 'volume']:\n",
        "        if col_name not in df.columns:\n",
        "          if col_name == 'volume':\n",
        "            df['volume'] = 0\n",
        "          else:\n",
        "            df[col_name] = df['close']\n",
        "\n",
        "      df['asset'] = ticker\n",
        "      df = df[['date', 'open', 'high', 'low', 'close', 'volume', 'asset']]\n",
        "      data[ticker] = df.copy()\n",
        "      print(f\"Loaded {ticker}: {len(df)} rows\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading {ticker}: {e}\")\n",
        "\n",
        "  return data\n",
        "\n",
        "# fetching data for all tickers\n",
        "all_data = fetch_crypto_data(tickers, days_to_fetch)\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "  \"\"\"\n",
        "  Calculating technical indicators including RSI, MACD, moving averages,\n",
        "  Bollinger Bands, momentum, and custom interaction features.\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "\n",
        "  # momentum indicators\n",
        "  df['rsi_14'] = ta.momentum.rsi(df['close'], window=14)\n",
        "  df['rsi_7'] = ta.momentum.rsi(df['close'], window=7)\n",
        "  df['macd'] = ta.trend.macd_diff(df['close'])\n",
        "  df['momentum'] = ta.momentum.roc(df['close'], window=10)\n",
        "\n",
        "  # moving averages\n",
        "  df['sma_7'] = ta.trend.sma_indicator(df['close'], window=7)\n",
        "  df['ema_7'] = ta.trend.ema_indicator(df['close'], window=7)\n",
        "  df['sma_14'] = ta.trend.sma_indicator(df['close'], window=14)\n",
        "  df['ema_14'] = ta.trend.ema_indicator(df['close'], window=14)\n",
        "\n",
        "  # volatility indicators\n",
        "  df['vol_7'] = df['close'].rolling(7).std()\n",
        "  df['bb_width'] = (ta.volatility.bollinger_hband(df['close'], window=20) -\n",
        "                    ta.volatility.bollinger_lband(df['close'], window=20)) / df['close']\n",
        "  df['bb_position'] = ((df['close'] - ta.volatility.bollinger_lband(df['close'], window=20)) /\n",
        "                       (ta.volatility.bollinger_hband(df['close'], window=20) -\n",
        "                        ta.volatility.bollinger_lband(df['close'], window=20)))\n",
        "\n",
        "  # price change features\n",
        "  df['ret_1'] = df['close'].pct_change()\n",
        "  df['ret_3'] = df['close'].pct_change(3)\n",
        "  df['high_3'] = df['high'].rolling(3).max()\n",
        "  df['low_3'] = df['low'].rolling(3).min()\n",
        "  df['range_3'] = (df['high_3'] - df['low_3']) / df['close']\n",
        "\n",
        "  # interaction features capturing combined signals\n",
        "  df['rsi_macd_interaction'] = df['rsi_14'] * df['macd']\n",
        "  df['momentum_volatility_ratio'] = df['momentum'] / (df['vol_7'] + 1e-5)\n",
        "  df['sma_crossover'] = (df['sma_7'] - df['sma_14']) / df['close']\n",
        "\n",
        "  # lagged features for temporal patterns\n",
        "  for col in ['rsi_14', 'macd', 'sma_7', 'bb_width']:\n",
        "    df[f'{col}_lag1'] = df[col].shift(1)\n",
        "\n",
        "  return df\n",
        "\n",
        "# calculating indicators for all assets\n",
        "for ticker in all_data:\n",
        "  all_data[ticker] = calculate_technical_indicators(all_data[ticker])\n",
        "\n",
        "def create_target_labels(df):\n",
        "  \"\"\"\n",
        "  Creating binary target labels for next-day price direction.\n",
        "  Target = 1 if next day close > today close, else 0.\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "  df['next_close'] = df['close'].shift(-1)\n",
        "  df['target'] = (df['next_close'] > df['close']).astype(int)\n",
        "  return df\n",
        "\n",
        "def create_significant_move_target(df, threshold=0.005):\n",
        "  \"\"\"\n",
        "  Creating binary labels for significant price moves.\n",
        "  Target = 1 if return > threshold, 0 if return < -threshold, NaN otherwise.\n",
        "  \"\"\"\n",
        "  df = df.copy()\n",
        "  df['next_close'] = df['close'].shift(-1)\n",
        "  df['next_return'] = (df['next_close'] - df['close']) / df['close']\n",
        "  df['target_big_move'] = np.where(df['next_return'] > threshold, 1,\n",
        "                                    np.where(df['next_return'] < -threshold, 0, np.nan))\n",
        "  return df\n",
        "\n",
        "# creating target labels with asset-specific thresholds\n",
        "for ticker in all_data:\n",
        "  all_data[ticker] = create_target_labels(all_data[ticker])\n",
        "  config = asset_config.get(ticker, asset_config['default'])\n",
        "  all_data[ticker] = create_significant_move_target(all_data[ticker],\n",
        "                                                    threshold=config['threshold_big_move'])\n",
        "\n",
        "def expanding_window_split(df, min_train=10, test_size=1, step=1):\n",
        "  \"\"\"\n",
        "  Generating train-test splits using expanding window approach.\n",
        "  Training set growing while test set moving forward one day at a time.\n",
        "  \"\"\"\n",
        "  n = len(df)\n",
        "  i = min_train\n",
        "  while i + test_size <= n:\n",
        "    train_idx = range(0, i)\n",
        "    test_idx = range(i, i + test_size)\n",
        "    yield df.iloc[train_idx], df.iloc[test_idx]\n",
        "    i += step\n",
        "\n",
        "# hyperparameter grid for logistic regression\n",
        "lr_grid = {'penalty': ['l2'], 'C': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "def train_and_evaluate(df, features, target_col, min_train=10, test_size=1, model_type='lr'):\n",
        "  \"\"\"\n",
        "  Training logistic regression model using expanding window validation.\n",
        "  Returning predictions and actual labels across all test windows.\n",
        "  \"\"\"\n",
        "  predictions = []\n",
        "  actuals = []\n",
        "  scaler = StandardScaler()\n",
        "\n",
        "  for train, test in expanding_window_split(df, min_train, test_size):\n",
        "    X_train = train[features].dropna()\n",
        "    y_train = train.loc[X_train.index, target_col]\n",
        "    X_test = test[features].dropna()\n",
        "    y_test = test.loc[X_test.index, target_col]\n",
        "\n",
        "    # skipping if insufficient data or single class\n",
        "    if len(X_train) == 0 or len(X_train) < min_train or y_train.nunique() < 2 or len(X_test) == 0:\n",
        "      continue\n",
        "\n",
        "    # scaling features\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # training logistic regression with grid search\n",
        "    if model_type in ('all', 'lr'):\n",
        "      model = GridSearchCV(\n",
        "        LogisticRegression(max_iter=500, class_weight='balanced'),\n",
        "        lr_grid,\n",
        "        scoring='f1',\n",
        "        cv=TimeSeriesSplit(n_splits=3)\n",
        "      )\n",
        "      model.fit(X_train_scaled, y_train)\n",
        "      y_pred = model.predict(X_test_scaled)\n",
        "      predictions.extend(y_pred.tolist())\n",
        "      actuals.extend(y_test.tolist())\n",
        "\n",
        "  return predictions, actuals\n",
        "\n",
        "# evaluating models for all assets\n",
        "print(\"\\nCryptocurrency Price Direction Prediction Results\\n\")\n",
        "\n",
        "results = {}\n",
        "for ticker, df in all_data.items():\n",
        "  # getting asset-specific settings\n",
        "  config = asset_config.get(ticker, asset_config['default'])\n",
        "  features = asset_features.get(ticker, asset_features['default'])\n",
        "\n",
        "  # preparing data using most recent days\n",
        "  df_recent = df.dropna(subset=['target']).iloc[-model_days:]\n",
        "  df_clean = df_recent.dropna(subset=features + ['target'])\n",
        "\n",
        "  if len(df_clean) < 15:\n",
        "    print(f\"\\n{ticker}: Insufficient data, skipping\")\n",
        "    continue\n",
        "\n",
        "  # training and evaluating for normal direction prediction\n",
        "  print(f\"\\n{ticker} - Next-Day Direction\")\n",
        "  print(f\"  Training window: {config['min_train']} days, Features: {len(features)}\")\n",
        "\n",
        "  preds, acts = train_and_evaluate(df_clean, features, 'target',\n",
        "                                   min_train=config['min_train'],\n",
        "                                   test_size=1,\n",
        "                                   model_type=config['model_type'])\n",
        "\n",
        "  # checking if both classes present in actuals\n",
        "  if len(np.unique(acts)) < 2:\n",
        "    print(f\"  Only one class present, skipping\")\n",
        "    continue\n",
        "\n",
        "  # calculating metrics\n",
        "  precision = precision_score(acts, preds)\n",
        "  recall = recall_score(acts, preds)\n",
        "  f1 = f1_score(acts, preds)\n",
        "  accuracy = np.mean(np.array(acts) == np.array(preds))\n",
        "\n",
        "  # skipping reporting if configured and F1 is zero\n",
        "  if config['skip_if_zeros'] and f1 == 0:\n",
        "    print(f\"  Skipped - insufficient signal for prediction\")\n",
        "    continue\n",
        "\n",
        "  print(f\"  Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, Accuracy: {accuracy:.3f}\")\n",
        "\n",
        "  results[ticker] = {\n",
        "    'precision': precision,\n",
        "    'recall': recall,\n",
        "    'f1': f1,\n",
        "    'accuracy': accuracy\n",
        "  }\n",
        "\n",
        "  # evaluating for significant move prediction\n",
        "  df_big_move = df.dropna(subset=['target_big_move']).iloc[-model_days:]\n",
        "  df_big_clean = df_big_move.dropna(subset=features + ['target_big_move'])\n",
        "\n",
        "  if df_big_clean['target_big_move'].notnull().sum() > 12:\n",
        "    print(f\"\\n{ticker} - Significant Moves (±{config['threshold_big_move']*100:.1f}%)\")\n",
        "\n",
        "    preds_big, acts_big = train_and_evaluate(df_big_clean, features, 'target_big_move',\n",
        "                                              min_train=config['min_train'],\n",
        "                                              test_size=1)\n",
        "\n",
        "    # filtering out NaN values\n",
        "    valid_idx = [i for i, val in enumerate(acts_big) if val in (0, 1)]\n",
        "    preds_filtered = [preds_big[i] for i in valid_idx]\n",
        "    acts_filtered = [acts_big[i] for i in valid_idx]\n",
        "\n",
        "    if len(acts_filtered) > 0 and len(np.unique(acts_filtered)) > 1:\n",
        "      prec_big = precision_score(acts_filtered, preds_filtered)\n",
        "      rec_big = recall_score(acts_filtered, preds_filtered)\n",
        "      f1_big = f1_score(acts_filtered, preds_filtered)\n",
        "      acc_big = np.mean(np.array(acts_filtered) == np.array(preds_filtered))\n",
        "      print(f\"  Precision: {prec_big:.3f}, Recall: {rec_big:.3f}, F1: {f1_big:.3f}, Accuracy: {acc_big:.3f}\")\n",
        "\n",
        "# printing summary statistics\n",
        "if results:\n",
        "  print(\"\\n\\nSummary Statistics\")\n",
        "\n",
        "  avg_precision = np.mean([v['precision'] for v in results.values()])\n",
        "  avg_recall = np.mean([v['recall'] for v in results.values()])\n",
        "  avg_f1 = np.mean([v['f1'] for v in results.values()])\n",
        "  avg_accuracy = np.mean([v['accuracy'] for v in results.values()])\n",
        "\n",
        "  print(f\"\\nAverage Performance:\")\n",
        "  print(f\"  Precision: {avg_precision:.3f}\")\n",
        "  print(f\"  Recall: {avg_recall:.3f}\")\n",
        "  print(f\"  F1-Score: {avg_f1:.3f}\")\n",
        "  print(f\"  Accuracy: {avg_accuracy:.3f}\")\n",
        "  print(f\"\\nAssets Evaluated: {len(results)} out of 10\")\n",
        "\n",
        "  best = max(results.items(), key=lambda x: x[1]['f1'])\n",
        "  worst = min(results.items(), key=lambda x: x[1]['f1'])\n",
        "  print(f\"\\nBest Performer: {best[0]} (F1: {best[1]['f1']:.3f})\")\n",
        "  print(f\"Weakest Performer: {worst[0]} (F1: {worst[1]['f1']:.3f})\")\n",
        "\n",
        "  print(\"\\nModeling complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1uY27hLYuoen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}